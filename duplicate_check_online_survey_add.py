import pandas as pd
from sqlalchemy import create_engine
import urllib
import datetime
import os

# --- 1. ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ ---
PROVINCE_CODES_TO_RUN = [
    '33', '34', '35', '36', '37', 
    '38', '39', '40', '42', '43', 
    '44', '45', '46', '47', '48', '49'
    ]  # << ‡∏£‡∏∞‡∏ö‡∏∏‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
SOURCE_TABLE = 'r_online_survey_chk_dup'  # ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ï‡∏±‡πâ‡∏á‡∏ï‡πâ‡∏ô (‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 1)
REFERENCE_TABLE = 'r_additional'           # ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• FI)
TARGET_TABLE = 'r_online_survey_dup_add'   # ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢

# --- ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Report ---
REPORT_FILENAME = 'C:/Users/NSO/Desktop/pop_run_data/duplicate_check/report_final_check.csv'
REPORT_COLUMNS = [
    'ProvCode', 'time_begin', 'time_end', 'time_difference',
    'rows_from_source', 'rows_in_reference', 'rows_found_as_new'
]

# --- ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ---
DB_SERVER = '192.168.0.203'
DB_NAME = 'pop6768'
DB_UID = 'pdan'
DB_PWD = 'P@ssw0rd12#$'

# ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô Key ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡πâ‡∏≥‡∏ã‡πâ‡∏≠‡∏ô
key_columns = [
    'NsoBuilding_No', 'RegCode', 'ProvCode', 'DistCode', 'SubDistCode', 'VilCode',
    'EA_Code_15', 'BuildingType', 'HouseNumber', 'RoomNumber', 'FirstName', 'LastName'
]

# --- 2. ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£ ---
sql_conn = None
try:
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á Engine ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
    quoted_password = urllib.parse.quote_plus(DB_PWD)
    engine_url = f"mssql+pyodbc://{DB_UID}:{quoted_password}@{DB_SERVER}/{DB_NAME}?driver=ODBC+Driver+17+for+SQL+Server"
    engine = create_engine(engine_url)
    sql_conn = engine.connect()
    print("‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")

    for prov_code in PROVINCE_CODES_TO_RUN:
        time_begin = datetime.datetime.now()
        print(f"\n--- ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î: {prov_code} | ‡πÄ‡∏ß‡∏•‡∏≤: {time_begin:%H:%M:%S} ---")

        # ========================= ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ö r_additional =========================
        
        print(f"[{prov_code}] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å '{SOURCE_TABLE}'...")
        query_source = f"SELECT * FROM {SOURCE_TABLE} WHERE ProvCode = '{prov_code}'"
        df_source = pd.read_sql(query_source, sql_conn)

        print(f"[{prov_code}] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å '{REFERENCE_TABLE}'...")
        query_ref = f"SELECT {', '.join(key_columns)} FROM {REFERENCE_TABLE} WHERE ProvCode = '{prov_code}'"
        df_reference = pd.read_sql(query_ref, sql_conn)
        
        rows_source_count = len(df_source)
        rows_reference_count = len(df_reference)

        print(f"[{prov_code}] ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö: {rows_source_count:,} ‡πÅ‡∏ñ‡∏ß | ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á: {rows_reference_count:,} ‡πÅ‡∏ñ‡∏ß")

        if df_source.empty:
            print(f"[{prov_code}] üü° ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô '{SOURCE_TABLE}' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•")
            df_new_records = pd.DataFrame()
        elif df_reference.empty:
            print(f"[{prov_code}] üü° ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡πÉ‡∏ô '{REFERENCE_TABLE}', ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏∂‡∏á‡∏ñ‡∏∑‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà")
            df_new_records = df_source.copy()
        else:
            print(f"[{prov_code}] ‡∏≠‡∏¢‡∏π‡πà‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
            df_source['composite_key'] = df_source[key_columns].fillna('').astype(str).sum(axis=1)
            df_reference['composite_key'] = df_reference[key_columns].fillna('').astype(str).sum(axis=1)
            
            existing_keys = set(df_reference['composite_key'])
            df_new_records = df_source[~df_source['composite_key'].isin(existing_keys)].copy()
        
        rows_new_records_count = len(df_new_records)
        if 'composite_key' in df_new_records.columns:
            df_new_records.drop(columns=['composite_key'], inplace=True)
            
        print(f"[{prov_code}] üü¢ ‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥‡∏à‡∏≥‡∏ô‡∏ß‡∏ô {rows_new_records_count:,} ‡πÅ‡∏ñ‡∏ß")
        
        # ========================= ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 3: ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏•‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà =========================
        
        if not df_new_records.empty:
            print(f"[{prov_code}] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡∏•‡∏á‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á '{TARGET_TABLE}'...")
            df_new_records.to_sql(
                name=TARGET_TABLE,
                con=engine,
                if_exists='append',  # ‡∏ô‡∏≥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ‡∏ï‡πà‡∏≠‡∏ó‡πâ‡∏≤‡∏¢‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏î‡∏¥‡∏°
                index=False,
                chunksize=1000
            )
            print(f"[{prov_code}] ‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
        else:
            print(f"[{prov_code}] üü° ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏´‡πâ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å")

        # ========================= ‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Report =========================
        time_end = datetime.datetime.now()
        time_difference = time_end - time_begin

        report_data = {
            'ProvCode': prov_code,
            'time_begin': time_begin.strftime('%Y-%m-%d %H:%M:%S'),
            'time_end': time_end.strftime('%Y-%m-%d %H:%M:%S'),
            'time_difference': str(time_difference),
            'rows_from_source': rows_source_count,
            'rows_in_reference': rows_reference_count,
            'rows_found_as_new': rows_new_records_count
        }
        
        report_df = pd.DataFrame([report_data], columns=REPORT_COLUMNS)
        
        report_df.to_csv(
            REPORT_FILENAME,
            mode='a',
            header=not os.path.exists(REPORT_FILENAME),
            index=False,
            encoding='utf-8-sig'
        )
        print(f"[{prov_code}] ‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Report ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå '{REPORT_FILENAME}' ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢ | ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤: {time_difference}")

except Exception as e:
    print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡πâ‡∏≤‡∏¢‡πÅ‡∏£‡∏á: {e}")
finally:
    if sql_conn:
        sql_conn.close()
        print("\n‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")